AWS Summit을 다녀와서 간단하게 후기를 남겨본다.

근 2년만에 AWS Summit에 참석한 것 같다. 1년 사이에 뭐 크게 달라진게 있겠어 라는 마음으로 한 동안 참석을 안했던 것 같다.
오랜만에 참석한 AWS Summit은 거짓말 보태서 조금 충격적이였고 그 사이에 AWS의 많은 기술들이 출시되었고 많은 세션들과
EXPO 또한 흥미로웠다.

첫째날은 업무 땜에 참석하지 못했고 둘째날 참석을 했는데 시간을 조절 못하고(?) 일찍 가는 바람에 선착순 100명에 들어서 크레딧 교환권을 받았다.
크게 필요 없을 것 같아서 팀분에게 양도했다.
<img src="https://user-images.githubusercontent.com/7076334/56429227-23e57900-62fd-11e9-9235-268d8f681245.jpg" width="500" height="300" />

내가 관심 있어 했던 세션은 다음과 같았다.


- 09:00 - 천만 사용자를 위한 AWS 클라우드 아키텍처 진화하기
- 11:10 - AWS Lambda 내부 동작 방식
- 13:00 - 서버리스 기반 콘텐츠 추천
- 14:10 - AWS에서 Kubernetes
- 16:20 - 진화하는 CloudFront의 이해와 글로벌 서비스 활용
- 17:20 - Elasticsearch를 통한 Full-text 및 로그 분석 기반 데이터 통찰력


각 각의 세션의 감상평을 간단하게 적어 보았다.


## 09:00 - 천만 사용자를 위한 AWS 클라우드 아키텍처 진화하기
<img src="https://user-images.githubusercontent.com/7076334/56430617-d15a8b80-6301-11e9-87ee-056cb0f9d2ad.jpg" width="500" height="300">
생각보다 재미있게 들었다. 사용자 수에 따른 AWS 클라우드 아키텍처를 어떻게 설계해야 되나 풀어서 설명했다.

##### 사용자 한명일 때
<img src="https://user-images.githubusercontent.com/7076334/56430883-d3711a00-6302-11e9-899f-3e0dde521c72.jpg" width="500" height="300">
Route53에 EIP 연결한 EC2 인스턴스의 형태로 매우 간단하다. 처음 단계기 때문에 굳이 큰 인스턴스를 사용할 필요도 없고 t 시리즈로 시작해서
실제 서비스 할때 상위 인스턴스로 변경하면 된다.

##### 사용자 수 > 1
<img src="https://user-images.githubusercontent.com/7076334/56431260-1089dc00-6304-11e9-97ab-5a39d5412254.jpg" width="500" height="300">
<img src="https://user-images.githubusercontent.com/7076334/56431680-98241a80-6305-11e9-8fd3-4c52d9a4e3ab.jpg" width="500" height="300">
이제 사용자가 생겼으니 DB를 사용해야 되는데 RDB를 사용할 것이냐 NoSQL을 사용할 것이냐 고민이 생기기 시작한다. 여기서 제시한 방법은 처음에는 RDB를 사용하고 규모가 커지면 (연간 데이터 크기 > 5 TB) NoSQL을 사용하는 것이다.

##### 사용자 수 > 100
<img src="https://user-images.githubusercontent.com/7076334/56432324-dfaba600-6307-11e9-8785-aaa637847ef3.png" width="500" height="300">
사용자 수 100명이 넘어가면 AWS에서 제공하는 RDS를 추천했는데 이유는 관리 포인트(확장, 모니터링)가 줄어들기 때문이다. 물론 EC2에 직접 설치하는 것보다 요금은 더 나온다

##### 사용자 수 > 1,000
<img src="https://user-images.githubusercontent.com/7076334/56432457-5d6fb180-6308-11e9-96ef-2d240f98edaf.jpg" width="500" height="300">
1000명이 넘어가는 시점에는 ELB를 통해서 가용영역(AZ)를 다르게 해서 이중화를 처리한다. 부하를 분산하고 확장에 용이하게 한다.

##### 사용자 수 > 10,000
<img src="https://user-images.githubusercontent.com/7076334/56432642-1930e100-6309-11e9-945a-f83596a43614.jpg" width="500" height="300">
DB 확장을 하고 리플리케이션을 통해 read, write를 나눈다. 그리고 정적 컨텐츠는 S3와 CDN을 이용해서 오리진의 부담을 덜어준다. (요금도 줄여줌)
그리고 ElasticCache (Memcached, Redis)를 이용해서 DB의 부하를 줄여준다.
NoSQL을 도입해볼 시기다. AWS에서는 DynamoDB라는 Document NoSQL을 지원한다.
CloudWatch 지표 기반을 통해 오토 스케일링을 할 수 있다.

##### 사용자 수 > 500,000
<img src="https://user-images.githubusercontent.com/7076334/56433360-8d6c8400-630b-11e9-8cb2-1dc15fe24422.jpg" width="500" height="300">
AWS 서비스를 통해 인프라 자동화를 시킨다. (Ci/CD, AWS Systems Manager)
CloudWatch를 통해 모니터링(알람, 대시보드)
기존 모놀리틱 아키텍처에서 SOA나 MSA를 고려해 본다.
그리고 SQS등을 이용해 결합도를 낮추고, 람다를 통한 서버리스도 도입해 본다.

##### 사용자 수 > 1,000,000
<img src="https://user-images.githubusercontent.com/7076334/56433656-99a51100-630c-11e9-930e-9090a6e7a493.jpg" width="500" height="300">
각 기능별로 오토스케일링(내부,외부), Multi-AZ

##### 사용자 수 5,000,000 ~ 10,000,000
<img src="https://user-images.githubusercontent.com/7076334/56433750-f4d70380-630c-11e9-8a26-b3abe867de46.jpg" width="500" height="300">
이 정도 되면 데이터베이스 이슈가 생김. 파티셔닝, 샤딩등 적용

##### 사용자 수 > 10,000,000
<img src="https://user-images.githubusercontent.com/7076334/56433823-41224380-630d-11e9-98d8-3ef646698044.jpg" width="500" height="300">
어플리케이션 튜닝, 많은 영역을 MSA 전환, 멀티 리전 등

물론 위 내용들이 100% 정답은 아닐 수 있다. 하지만 참고할 만한 지표가 있다는 것에 의의를 둔다.
https://www.slideshare.net/awskorea/aws-aws-aws-summit-seoul-2019-141252077


## 11:10 - AWS Lambda 내부 동작 방식
10분 전에 도착하니까 이미 많은 사람들이 줄을 서 있었고 세션 시작 시간이 되었는데도 문을 오픈하지 않았다. 확인해 보니 이미 만석이되서 문을 닫고 있었던 것이다. 가장 듣고 싶었던 세션이였는데 사람이 너무 많아서 입장을 못했다 ㅠㅠ
https://www.slideshare.net/awskorea/aws-lambda-aws-aws-summit-seoul-2019


## 13:00 - 서버리스 기반 콘텐츠 추천
<img src="https://user-images.githubusercontent.com/7076334/56458719-3cb96180-63c5-11e9-81b9-9d574bfd5b76.jpg" width="500" height="300">
이번에 AWS Summit 가장 많이 들리는 키워드 중 하나가 서버리스랑 ML(Machine Running) 이였는데 이번 세션에서는 그 둘의 내용이 모두 포함되어 있었다. 보통 ML라고 하면 어렵다고 많이 생각하는데 발표자 분은 자기가 만들려고 하는 알고리즘은 왠만하면 구글검색으로 찾을 수 있다고 했다. 그리고 아마존 추천 PDF를 예로 보여줬는데 어떤 화면에서 어떤 기술이 사용되었는지 명확하게 정리되어 있었다.
그래서 발표자 분이 생각하는 콘텐츠 추천 부분은 ML보다 어떻게 프로덕션에 올려야 되나가 더 어려운것 같다고 하며 여러 서버리스 관련 기술들을 설명해 주었다.
람다나 아테나 S3, DDB등 예전에 사용해 보았던 기술들이 나와서 반갑기도 했고 이런식으로도 서버리스 할 수 있구나라는 것을 느꼈다.

<img src="https://user-images.githubusercontent.com/7076334/56458770-b81b1300-63c5-11e9-8b79-35b51ed2afbf.png" width="500" height="300">
일단 단계를 이렇게 4단계 (데이터 수집, 데이터 처리, 추천, 사용자 평가)로 나누어 반복적으로 처리 작업을 하면서 비 Regression 추천 모델을 완전히 서버리스 형태로... Regression 추천 모델도 거의 서버리스 형태로 동작 시키는 부분에 대해서 설명해 주었다.

##### 비 Regression
<img src="https://user-images.githubusercontent.com/7076334/56458880-f9f88900-63c6-11e9-8f9b-2cc93ee7295d.jpg" width="500" height="300">
해당 과정들을 거쳤는데 Lambda에서 미리 Validate를 체크해서 데이터를 정재를 시켜 놓는것 같았다.
그리고 Kinesis Firehose를 이용해서 S3로 Gzip 형태로 저장하는데 Gzip을 사용하면 데이터양이나 요금면에서 차이가 많이 난다고 한다.
아테나를 통해 S3에 저장한 Gzip 데이터를 조회해서 처리. EC2, Redshift 등에서 처리해도 되지만 아테나로 조회 하면 DATA SCAN에 대한 과금만 Gzip 인 경우 압축된 사이즈 기준으로 과금된다고 한다.
그리고 유저에게 추천 데이터를 보여주기 위해 아테나의 결과를 DDB나 AuroraDB로 적재 한다고 한다. 물론 S3에서 해당 부분으로 적재하는것도 다 자동으로 서버리스. (Aurora는 LOAD DATA FROM S3, DDB는 streaming from S3 로 자동으로 데이터 적재할 수 있다.)

##### Regression
<img src="https://user-images.githubusercontent.com/7076334/56459110-12b66e00-63ca-11e9-8c69-2c00dbb4ceb9.jpg" width="500" height="300">
이 부분은 이해를 좀 못했는데 AWS에 있는 서비스는 사용하는것이 좋고 없는 경우 EMR, SageMaker을 사용하면 된다(?)
암튼 Regression도 거의 서버리스로 운영할 수 있다고 한다.

https://www.slideshare.net/awskorea/serverless-recommendation-ml


## 14:10 - AWS에서 Kubernetes
나는 쿠버네티스 관련해서 사용해본적이 아직 없다. 그런데 요즘 많이 보이는 기술중 하나인 것 같아서 세션을 참석했는데 쿠버네티스에 대한 설명보다는 이미 쿠버네티스를 사용해본 사람들 위주로 AWS에서 어떤 서비스로 적용할 수 있나 설명을 하는 세션이였다. 아무래도 쿠버네티스 사용 경험이 없다 보니 조금 이해도가 떨어지는 세션이였다. 아쉬웠다.
https://www.slideshare.net/awskorea/aws-kubernetes-aws-aws-summit-seoul-2019


## 16:20 - 진화하는 CloudFront의 이해와 글로벌 서비스 활용
<img src="https://user-images.githubusercontent.com/7076334/56470197-566aaf80-647e-11e9-9e5e-383237d61f3f.jpg" width="500" height="300">
예전에 CDN을 사용하지 않고 S3에 저장되어 있는 이미지를 그냥 사용했다가 폭탄 과금을 맞은 기억이 있다. 이후에 이미지를 압축해서 용량을 줄이고 CDN을 사용해서 과금을 많이 줄인 기억이 난다.
이번 세션은 관련해서 CDN + S3, CDN + EC2 등의 조합을 설명했는데 인상 깊었던 것은 Lambda@edge를 사용하여 원하는 이미지 사이즈가 없을 경우 리사이즈를 해서 자동으로 보낼 수 있다는 것이다. 예전에는 직접 이미지를 압축해서 해당 사이즈의 이미지를 만들어 놓았는데 그럴 필요가 없을 것 같다.

<img src="https://user-images.githubusercontent.com/7076334/56470243-1c4ddd80-647f-11e9-9667-e78a2d4fe210.jpg" width="500" height="300">


## 17:20 - Elasticsearch를 통한 Full-text 및 로그 분석 기반 데이터 통찰력
(정리중)

https://www.slideshare.net/awskorea/elasticsearch-fulltext-aws-aws-summit-seoul-2019
